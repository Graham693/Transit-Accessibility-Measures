---
title: "Travel Time Matrix to Maps"
output: html_notebook
---

## Notebook Purpose

This notebook serves to summarize the entire visualization process going from 
the travel time matrix to the visualizations. That involves the following 
sections:

1) Travel Time Matrix Wrangling
2) Score Computation
3) Isochrone Computation
4) Dataset Wrangling Part II (NA Insertion)
5) Interactive Visualization
6) Map HTML Exports

## 0) Useful Libraries

```{r message=FALSE, warning=FALSE, include=TRUE}
# wrangling/convenience
library(tidyverse)
library(glue)
library(stringr)
library(sf)
library(data.table)

# visualization
library(leaflet)
library(mapview); mapviewOptions(platform = 'leafgl')
#library(ggplot2)
#library(RColorBrewer)
#library(scales)
#library(lattice)

# For pretty knitting
library(lemon)
knit_print.data.frame <- lemon_print
knit_print.tbl <- lemon_print
knit_print.summary <- lemon_print
```





## 1) Data Wrangling

### Import all dissemination block data
```{r}
# import dissemination blocks and keep id and pop columns
origins <- fread(file.path("../data/clean", "vancouver_db.csv"))[, .(id, pop)]
origins$pop <- str_replace_all(origins$pop, ',', '')

# change col types
origins$pop <- as.numeric(origins$pop)  
origins$id <- as.factor(origins$id)  

n_origins <- nrow(origins)
paste('Origin Rows: ', n_origins)

# Peek
head(origins)
```


### Import all amenity data
```{r}
# import amenities (Cultural/Art facilities)
destinations <- fread(file.path("../data/clean", "vancouver_facilities_2.csv"))

# see summary counts of each amenity
destinations %>% group_by(type) %>% summarise(count = n()) %>% arrange(desc(count))

# clean amenities / filter types to keep 4 most frequent amenities
target_amenities <- c('gallery', 'museum', 'library or archives', 'theatre/performance and concert hall')
destinations <- destinations %>% filter(type %in% target_amenities)
# keep only id and type columns
destinations <- destinations[ , .(id, type)]
# change col types
destinations$type <- as.factor(destinations$type)
destinations$id <- as.factor(destinations$id)  

n_amenities <- nrow(destinations)
paste('Destinations: ', n_amenities)
head(destinations)
```


### Import the travel time matrix
```{r kable.opts=list(caption='Summary Table')}
# import travel time matrix
ttm <- fread(file.path('../data/clean', 'ttm.csv'))

# convert Ids to  factor
ttm$fromId <- as.factor(ttm$fromId)
ttm$toId <- as.factor(ttm$toId)

## Replace travel times less than 1 minute to 1 minute
# This is done to prevent infinity values in the scoring since
# 1 minute is still a reasonable time for trips in the 0 - 1 min range.
ttm$avg_time <- pmax(ttm$avg_time, 1)

# add amenity types
# use left join since we only care to keep existing amenities in the ttm
ttm <-  left_join(ttm, destinations, by = c('toId' = 'id'))

# how many origins actually have transit accessibility
paste('Origins considered:', round((length(unique(ttm$fromId))/n_origins)*100, 2), '%')
paste('Destinations considered:', round(length(unique(ttm$toId))/n_amenities*100, 2), '%')
paste('Rows = ', nrow(ttm))

# peek
head(ttm)
```



### Import amenity weights but they still have issues:

There are **duplicates** on IDs 4180 and 4181.

Additionally, of all amenity IDs in the travel time matrix, not all are found
in the weight set.

```{r}
# import amenity weights
amenity_wts <- read.csv('../data/amenity_weights/amenity_wts.csv')

# clean weights
amenity_wts <- amenity_wts[, c('id', 'Index')]
names(amenity_wts) <- c('id', 'weight')
amenity_wts$id <-  as.factor(amenity_wts$id)

# see weight distribution
#plot(density(amenity_wts$weight), main = 'Amenity Popularity Distribution')

amenity_wts %>% group_by(id) %>% summarize(n = n()) %>% arrange(desc(n))

# are all the ttm amenity IDs in the weighted IDs set?
paste('Are all the ttm amenity IDs in the weighted IDs set? (needs to be true for the join to work)')
all(unique(ttm$toId) %in% unique(amenity_wts$id))


# join when weight index is corrected
#destinations <- left_join(destinations, amenity_wts, by = c('id' = 'id'))

```


### Isochrone Frame and Types
```{r}

# only consider the nearest amenity
isochrone_frame <- ttm %>%
  group_by(fromId, type) %>%
  summarise(avg_time = min(avg_time))

# isochrone frame
isochrone_frame$time_groups <-  with(isochrone_frame,
                                   ifelse(avg_time < 15, "15",
                                   ifelse(avg_time < 30, "30",
                                   ifelse(avg_time < 45, "45",
                                   ifelse(avg_time < 60, "60",
                                   ifelse(avg_time < 75, "75",
                                   ifelse(avg_time < 90, "90", "90+")))))))

isochrone_frame <- isochrone_frame[, c(1,2,4)]
head(isochrone_frame)
```
```{r}

# see how many trips in each time_group
isochrone_frame %>% group_by(time_groups) %>% summarise(n = n()) -> t_groups

plot(t_groups$n, type = 'b')
```


### Import the dissemination block shape file
```{r}
canada_shape <- st_read("../data/census2016_DBS_shp/DB_Van_CMA/DB_Van_CMA.shp", stringsAsFactors = FALSE)

# select a greater metropolitan area
metropolitan_area <- "Vancouver"

# filter columns and rows
vancouver_shape <- data.frame(canada_shape[which(canada_shape$CMANAME == metropolitan_area), c(1, 28)])

# id to factor
vancouver_shape$DBUID <- as.factor(vancouver_shape$DBUID)

paste('Rows = ', nrow(vancouver_shape))
head(vancouver_shape)
```






## 2) Score Computation

Notes: 

- We don't scale the data before score computation because we care about the
scale of time and standard deviation. We should use their values as is, 
otherwise scaling will give them equal weighing again when this is a bad
assumption.
- Log normalizing the score isn't important as the score visualization depends 
on the quantiles taken from the distribution of scores. Since log only shifts 
values, the visualizations will be identical.



```{r}
# import score functions
source('Updated_Score_Functions.R')

score_list <- list()
i <- 1

for (n in c(1, 2, 3, 4)) {
  
  if (n == 4) { n <- NULL }
  score <- sum_score_fxn(ttm, nearest_n = n, weight = FALSE, log_normalize_score = FALSE)
  score_list[[i]] <- score
  i <- i+1
  
}

scores_long <- rbindlist(score_list) %>% arrange(fromId, nearest_n)

scores_long

```



## 3) Dataset Wrangling Part II (NA Insertion)

Each origin(fromId) should have x different scores based on the possible 
equation below:

*In the current file*
1 weight options * 4 amenity options * 4 nearest options = 16

*In the future*
2 weight options * 4 amenity options * 4 nearest options = 32


Many zones however don't have any routes, such as provincial parks which aren't
linked to via transit. To visualize them in the data we need to attribute these
cases an NA value. Since these rows are missing we'll use the following code
to re-add those NA values.

```{r}
# target zone count
x <- 16

# check for the inconsistency in values
counted <- scores_long %>% group_by(fromId) %>% summarize(n = n()) %>% arrange(n) 

# check for current unique counts to make sure it's multiples of the type number
paste('Unique counts: '); unique(counted$n)

# get expected rows by multiplying unique IDs by x
n_fromIds <- uniqueN(scores_long$fromId)
N <- n_fromIds*x

paste(glue('{nrow(scores_long)} of {N} rows filled ({round((nrow(scores_long) / N)*100, 2)}%)'))
paste(N - nrow(scores_long), 'to fill.')
```

```{r}

# function for NA grid expansion 
NA_grid_maker <- function(id, df, isochrone = FALSE) {
  
  all_amenities <- as.character(unique(df$type))
  
  # get missing amenities by indexing the fromId and keeping only unique types
  missing_amenities <- setdiff(all_amenities, unique(df$type[df$fromId == id]))

  if (isochrone == FALSE) {
    # create NA rows to append via expand.grid (creates a row for every factor combination)
    NA_rows <- expand.grid('fromId' = id,
                         'type' = missing_amenities,
                         'weight' = as.character(unique(df$weight)),
                         'nearest_n' = as.character(unique(df$nearest_n)),
                         'score' = NA, 
                         stringsAsFactors = TRUE)
  } else {
    # create NA rows to append via expand.grid (creates a row for every factor combination)
    NA_rows <- expand.grid('fromId' = id,
                         'type' = missing_amenities,
                         'time_groups' = NA, 
                         stringsAsFactors = TRUE)
  }
  
  NA_rows
}

# function for filling table with NA values
NA_table_filler <- function(df, custom_idx = NULL, isochrone = FALSE) {
  
  # count each fromId occurence
  fromId_counts <- df %>% group_by(fromId) %>% mutate(n = n())
  
  if (is.null(custom_idx)) {
    # create a fromId array using Ids that don't meet the [x] count requirement
    id_arr <- array(unique(fromId_counts[fromId_counts$n < x, ]$fromId))
  } else {
    id_arr <- custom_idx
  }
  
  # get rows
  filler_rows <- rbindlist(apply(id_arr, MARGIN = 1, FUN = NA_grid_maker, df = df, isochrone = isochrone))

  # append and order
  df <- rbindlist(list(df, filler_rows), use.names = TRUE) 
  
  if (isochrone == FALSE) {
    df <- df %>% arrange(fromId, type, nearest_n, weight)
  } else {
    df <- df %>% arrange(fromId, type)
  }
  
  df
}


partial_filled_scores_long <- NA_table_filler(scores_long)



```

Although, recall that not all origins were used in the score computation, 
so we need to add those NA values as well.

```{r}
missing_blocks <- array(setdiff(origins$id, partial_filled_scores_long$fromId))


# fill partial_filled_scores_long
filled_scores_long <- NA_table_filler(partial_filled_scores_long,
                                      custom_idx = missing_blocks)

# fill isochrone frame
filled_isochrone_frame <- NA_table_filler(isochrone_frame,
                                          custom_idx = missing_blocks,
                                          isochrone = TRUE)
```


Now lets add population data to the scores and isochrone frame

```{r}
# right join with origins to include origins without transit access

filled_scores_long <- right_join(filled_scores_long, origins, by = c('fromId' = 'id'))
filled_isochrone_frame <- right_join(isochrone_frame, origins, by = c('fromId' = 'id'))

nrow(isochrone_frame)
nrow(filled_isochrone_frame)

filled_isochrone_frame[is.na(filled_isochrone_frame$time_groups), ]
isochrone_viz_frame_st
```

```{r}

## Export checkpoint
write.csv(filled_scores_long, 'June2_scores_long.csv', row.names = FALSE)
write.csv(filled_isochrone_frame, 'June2_isochrone_frame.csv', row.names = FALSE)

```


## 4) Interactive Visualization
```{r}
# join factor and geometry data 
scores_viz_frame <- left_join(vancouver_shape, filled_scores_long, by = c('DBUID' = 'fromId'))
isochrone_viz_frame <- left_join(vancouver_shape, filled_isochrone_frame, by = c('DBUID' = 'fromId'))

# convert back to sf object
scores_viz_frame_sf <- st_as_sf(scores_viz_frame)
scores_viz_frame_st <- st_transform(scores_viz_frame_sf, crs = 4326)

isochrone_viz_frame_sf <- st_as_sf(isochrone_viz_frame)
isochrone_viz_frame_st <- st_transform(isochrone_viz_frame_sf, crs = 4326)

```


```{r}
# Mapping function
map_maker_scores <- function(data, amenity, weight, nearest_n) {
  
  amn_name <- amenity %>%
                str_to_title() %>%
                str_replace_all('Or', 'or') %>%
                str_replace('And', 'and') %>%
                str_replace('/Performance', '')
  
  print('Current Map:')
  print(glue('{amn_name} Transit Accessibility - Weighted ({weight}) - Nearest Amenities ({str_to_upper(nearest_n)})'))

  # subset info
  polyg_subset <- data[data$type == amenity & data$weight == weight & data$nearest_n == nearest_n, ]
  
  # score vector
  score_vec <- polyg_subset$score
  
  # colour palette 
  Rd2Gn <- c("#e30606", "#fd8d3c", "#ffe669", "#cdff5e", "#64ed56")
  pal_fun <- colorQuantile(palette = Rd2Gn, NULL, n = 5)
  
  # popup # percentile(score_vec),
  percentile <- ecdf(score_vec)
  p_popup <- paste0("<h2>Accessibility Percentile: ", round(percentile(score_vec), 2)*100, '%',"</h2>", 
                      "<br><strong>Block ID: ", polyg_subset$DBUID,"</strong>",
                      "<br><strong>Block Population: ", polyg_subset$pop,"</strong>",
                      "<br>Raw Score: ", round(score_vec, 2))
        
  map <- leaflet(data = polyg_subset) %>%
      addPolygons(
        stroke = FALSE,  # remove polygon borders
        fillColor = ~pal_fun(score_vec), # set fill colour with pallette fxn from aboc
        fillOpacity = 0.6, smoothFactor = 0.5, # aesthetics
        popup = p_popup) %>% # add message popup to each block
      addTiles() %>%
      setView(lng = -122.8, lat = 49.2, zoom = 11) %>%
      addLegend("bottomleft",  # location
                pal=pal_fun,    # palette function
                values=~score_vec,  # value to be passed to palette function
                title = glue('{amn_name} Transit Access'))
  
  file_name <- glue('{amn_name} Transit Accessibility - Weighted ({weight}) - Nearest Amenities ({str_to_upper(nearest_n)})')
  
  map
  #mapshot(map, url = paste0(getwd(), glue("/New HTML Maps/{file_name}.html")))

}



map_maker_isochrone <- function(data, amenity) {
  
  amn_name <- amenity %>%
                str_to_title() %>%
                str_replace_all('Or', 'or') %>%
                str_replace('And', 'and') %>%
                str_replace('/Performance', '')
  
  print('Current Map:')
  print(glue('{amn_name} Transit Isochrone'))

  # subset info
  polyg_subset <- data[data$type == amenity, ]
  
  # score vector
  time_groups <- polyg_subset$time_groups
  
  # colour palette 
  pal_fun <- colorFactor(
    palette = c("#3ef000", "#c5eb00", "#fbff00", "#e9cb00", "#e78600", "#e44200", "#e20000"),
    levels = sort(unique(polyg_subset$time_groups))
    )

  p_popup <- paste0("<h2>Time to the nearest:</h2>", 
                      "<br><strong>", amn_name,"</strong>",
                      "<br>",
                      "<br> = ", time_groups)
        
  map <- leaflet(data = polyg_subset) %>%
      addPolygons(
        stroke = FALSE,  # remove polygon borders
        fillColor = ~pal_fun(time_groups), # set fill colour with pallette fxn from aboc
        fillOpacity = 0.7, smoothFactor = 0.5, # aesthetics
        popup = p_popup) %>% # add message popup to each block
      addTiles() %>%
      setView(lng = -122.8, lat = 49.2, zoom = 11) %>%
      addLegend("bottomleft",  # location
                pal=pal_fun,    # palette function
                values=~time_groups,  # value to be passed to palette function
                title = glue('{amn_name} Transit Access'))
  
  file_name <- glue('{amn_name} Transit Isochrone')
  
  map
  #mapshot(map, url = paste0(getwd(), glue("/New HTML Maps/{file_name}.html")))

}


```

```{r}
isochrone_viz_frame_st[is.na(isochrone_viz_frame_st$time_groups), ]
isochrone_viz_frame_st

map_maker_isochrone(isochrone_viz_frame_st, 'gallery')

```



## 5) Map HTML Exports

```{r}

for (amenity in unique(scores_viz_frame_st$type)) { 
  
  # 4 isochrone maps
  map_maker_isochrone(data = isochrone_viz_frame_st, amenity)

  for (weight in unique(scores_viz_frame_st$weight)) {
    for (nearest_n in unique(scores_viz_frame_st$nearest_n)) {
      
      # 16 / 32 others
      map_maker_scores(data = scores_viz_frame_st, amenity, weight, nearest_n)
      
    }
  }
}
```



