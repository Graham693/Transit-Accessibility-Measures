---
title: "Many-to-Many Point Computation Script"
author: "Luka Vukovic"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

### Loading libraries
```{r include=FALSE}

# Main
library(r5r)
#if (Sys.getenv("JAVA_HOME")!="")
#  Sys.setenv(JAVA_HOME="")
library(rJava)
library(sf)
library(data.table)

# Visualization
library(ggplot2)
library(mapview); mapviewOptions(platform = 'leafgl')

# Convenience
library(tidyverse)
library(glue)
library(rlist)

```


### 1. Setup the Network Graph

- If the vancouver_canada.osm.pbf file needs to be converted to an .osm, one can use a binary osm converter available at: https://wiki.openstreetmap.org/wiki/Osmconvert#Binaries

```{r message=FALSE, warning=FALSE}
## Allocate 4G RAM to Java
options(java.parameters = "-Xmx6g")

## Build transport network, pointing to path where OSM and GTFS data are located
r5r_core <- setup_r5(data_path = getwd(), verbose = FALSE)
```


### 2. Load origin/destination points

```{r, warning=FALSE}

# Dissemination Blocks
origins <- fread(file.path("../../data/clean", "vancouver_db.csv"))
origins <- origins[, c(1,3,4)]
colnames(origins)[1] <- 'id'
origins$id <- as.character(origins$id)  # numeric to char

# Cultural/Art facilities
destinations <- fread(file.path("../../data/clean", "vancouver_facilities_2.csv"))
destinations <- destinations[, 1:3]

destinations$lat <-  as.numeric(destinations$lat) # char to numeric
destinations$lon <-  as.numeric(destinations$lon) # char to numeric
destinations$id <- as.character(destinations$id)  # numeric to char

destinations <- destinations[complete.cases(destinations)] # remove NA rows

# Peek
head(origins)
head(destinations)

# Check
c(nrow(origins), nrow(unique(origins[,1])))
c(nrow(destinations), nrow(unique(destinations[,1])))
```

```{r}
## Testing samples
#sample_origins <- origins[sample(.N, 3000)]
#sample_destinations <- destinations[sample(.N, 432)] # uses all destinations
#sample_origins
#sample_destinations
```


### 3. Set constraints

```{r}
# Non-transit : WALK, BICYCLE, CAR, BICYCLE_RENT, CAR_PARK
# Transit: TRAM, SUBWAY, RAIL, BUS, FERRY, CABLE_CAR, GONDOLA, FUNICULAR
mode <- c('WALK', 'TRANSIT')

max_walk_dist <- 1000 # 1 km

max_trip_duration <- 120 # 2 hours

max_rides <- 3 # max transfers

```


### 4. Compute Expanded Travel Time Matrix

- We average transit times across all weekly transit schedules so we compute travel time on:
  - A weekday
  - Saturday
  - Sunday
- We also want average transit times across time of day so we compute travel times from:
  - 7am to 7pm at every hour mark with a departure window of 30 minutes.
  - A window of 1 equates to a 5 minute departure window so we will use 6.

```{r}
# default walk speed = 3.6 km/h

all_ttms <- list()

for (day in 14:16) {          # May 14=Fri, 15=Sat, 16=Sun
  for (time in 7:19) {        # 7 to 19 hours
    
    departure_datetime <- as.POSIXct(glue("{day}-05-2021 {time}:00:00"), format="%d-%m-%Y %H:%M:%S")
    
    ttm <- travel_time_matrix(r5r_core = r5r_core,
                          origins = origins,
                          destinations = destinations,
                          departure_datetime = departure_datetime,
                          time_window = 30,
                          
                          # constrains
                          mode = mode,
                          max_walk_dist = max_walk_dist,
                          max_trip_duration = max_trip_duration,
                          max_rides = max_rides,
                          verbose = FALSE)
    
    all_ttms <-  list.append(all_ttms, ttm) # very slow: rbind(all_ttm, ttm)
    
    print(glue('Progress: {round(((day-14)*12 + time-6)/37*100, 1)}%'))
  }
}

# Fast way to bind all data.frames
TTM <- rbindlist(all_ttms)

print('COMPLETED')

summary(TTM)
```

```{r}
TTM_agg
```

### 5. Aggregate Travel Time Matrix without any Destination Weights

- In order to avoid NA or inf values in the score computation, we need to replace all standard deviations that are zero or NA with an appropriate value.
- A zero standard deviation can be replaced with the 1% quantile
- An NA standard deviation is due to there only being 1 sample in the computation. Since there's only a single possible trip we'll assume the variation in operation is higher than average, so the 80% quantile in variation will be used as replacement.

```{r}

# aggregate on each unique transit trip to computed the avg trip travel
# time to the same destination
TTM_agg <- TTM %>%
           group_by(fromId, toId) %>% 
           summarise(
             avg_unique_time = mean(travel_time), 
             sd_unique_time = sd(travel_time)
           )

print('First aggregation:'); summary(TTM_agg)

# fill NAs in standard deviation with 80th percentile value
upper80_sd <- quantile(TTM_agg$sd_unique_time, 0.8, na.rm=TRUE)
TTM_agg <- TTM_agg %>% replace_na(list('sd_unique_time'=upper80_sd))

# replace zero standard deviations to avoid infinity computations later on
lower01_sd <- quantile(TTM_agg$sd_unique_time, 0.01, na.rm=TRUE)
TTM_agg$sd_unique_time[(TTM_agg$sd_unique_time == 0)] <-  lower01_sd

print('First Aggregation with sd NAs+Zeros replaced:'); summary(TTM_agg)

# Export for later manipulation
write.csv(TTM_agg, "../../data/clean/ttm.csv", row.names = FALSE)

```

